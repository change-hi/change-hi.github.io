<!DOCTYPE html>
<html lang="en">
<head>
  <title> Change-HI/EDU | 1. Scikit-Learn </title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/css/themes/spacelab/bootstrap.min.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/syntax.css">
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link href="/css/fontawesome/css/fontawesome.css" rel="stylesheet">
  <link href="/css/fontawesome/css/brands.css" rel="stylesheet">
  <link href="/css/fontawesome/css/solid.css" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script>

  

  <!-- Load JQuery, then use it to attach the class 'active' to navbar item currently displayed. -->
  <script src="https://code.jquery.com/jquery-3.6.0.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script>
    $(window).on('load', function () {
      $('.nav-item').find('a[href="' + location.pathname + '"]').addClass('active');
    });
  </script>

</head>
<body>

<div class="navbar navbar-expand-lg fixed-top navbar-light bg-light">
  <div class="container">
    <a class="navbar-brand" href="/index.html"> Change-HI/EDU </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav">
        
        <li class="nav-item"><a class="nav-link" href="/modules/">Modules</a></li>
        
        <li class="nav-item"><a class="nav-link" href="/outcomes/">Outcomes</a></li>
        
        
        <li class="nav-item"><a class="nav-link" href="/readings/">Readings</a></li>
        
        
        <li class="nav-item"><a class="nav-link" href="/experiences/">Experiences</a></li>
        
        
        <li class="nav-item"><a class="nav-link" href="/assessments/">Assessments</a></li>
        
        
      </ul>
    </div>
  </div>
</div>

<!-- Internal fragment for displaying the breadcrumb bar -->
<div class="breadcrumb-background" style="padding-top: 1em; padding-bottom: .01em">
  <div class="container">
    <nav aria-label="breadcrumb">
      <ol class="breadcrumb">
        
        <li class="breadcrumb-item"><a href="/">Home</a></li>
        <li class="breadcrumb-item"><a href="/modules">Modules</a></li>
        <li class="breadcrumb-item"><a href="/modules/"></a></li>
        <li class="breadcrumb-item active">1. Scikit-Learn</li>
      </ol>
    </nav>
  </div>
</div>


<div class="container">
  <div class="alert alert-success mt-3" role="alert">
  <p><i class="fa-solid fa-globe fa-xl"></i> <strong>Overview</strong></p>
  <hr />

  <p><strong>Questions</strong></p>
  <ul>
    <li>How can we model environmental data with decision trees?</li>
  </ul>

  <p><strong>Objectives</strong></p>
  <ul>
    <li>Understand how to fit decision trees in SciKit-Learn</li>
  </ul>
</div>

<!-- <div class="alert alert-info" role="warning" markdown="1">
<i class="fa-solid fa-circle-info fa-xl"></i> **Jupyter Lab Binder**
<hr/>
**Note:** Click [here](https://mybinder.org/v2/gh/scikit-learn/scikit-learn/1.2.X?urlpath=lab/tree/notebooks/auto_examples/gaussian_process/plot_gpr_co2.ipynb) to download the full example code or to run this example in your browser via Binder
</div> -->

<h1 id="decision-trees-on-mauna-loa-co2-data">Decision Trees on Mauna Loa CO2 data</h1>

<p>This example uses data that consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppm)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 2001. The objective is to model the CO2 concentration as a function of the time <em>t</em>.</p>

<h3 id="build-the-dataset">Build the dataset</h3>

<p>We will derive a dataset from the Mauna Loa Observatory that collected air samples. We are interested in estimating the concentration of CO2 and extrapolate it for further year. First, we load the original dataset available in OpenML.</p>

<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">from sklearn.datasets import fetch_openml

co2 = fetch_openml(data_id=41187, as_frame=True, parser="pandas")
co2.frame.head()
</code></pre>
</div>
<p>First, we process the original dataframe to create a date index and select only the CO2 column.</p>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">import pandas as pd

co2_data = co2.frame
co2_data["date"] = pd.to_datetime(co2_data[["year", "month", "day"]])
co2_data = co2_data[["date", "co2"]].set_index("date")
co2_data.head()
</code></pre>
</div>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">co2_data.index.min(), co2_data.index.max()
</code></pre>
</div>
<p>Out: <code class="language-plaintext highlighter-rouge">(Timestamp('1958-03-29 00:00:00'), Timestamp('2001-12-29 00:00:00'))</code></p>

<p>We see that we get CO2 concentration for some days from March, 1958 to December, 2001. We can plot these raw information to have a better understanding.</p>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">import matplotlib.pyplot as plt

co2_data.plot()
plt.ylabel("CO$_2$ concentration (ppm)")
_ = plt.title("Raw air samples measurements from the Mauna Loa Observatory")
</code></pre>
</div>
<figure>
  
    <img src="/morea/machine-learning/fig/co2_data.png" style="max-width: 60%;" alt="/Basic%20Binder%20Webpage" class="img-fluid mx-auto d-block border" />
  
  <figcaption style="text-align: center">
    <small>
      
    </small>
  </figcaption>
</figure>

<p>We will preprocess the dataset by taking a monthly average and drop month for which no measurements were collected. Such a processing will have an smoothing effect on the data.</p>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">co2_data = co2_data.resample("M").mean().dropna(axis="index", how="any")
co2_data.plot()
plt.ylabel("Monthly average of CO$_2$ concentration (ppm)")
_ = plt.title(
    "Monthly average of air samples measurements\nfrom the Mauna Loa Observatory"
)
</code></pre>
</div>
<figure>
  
    <img src="/morea/machine-learning/fig/co2_data_smoothed.png" style="max-width: 60%;" alt="/Basic%20Binder%20Webpage" class="img-fluid mx-auto d-block border" />
  
  <figcaption style="text-align: center">
    <small>
      
    </small>
  </figcaption>
</figure>

<p>The idea in this example will be to predict the CO2 concentration in function of the date. We are as well interested in extrapolating for upcoming year after 2001.</p>

<p>As a first step, we will divide the data and the target to estimate. The data being a date, we will convert it into a numeric.</p>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">X = (co2_data.index.year + co2_data.index.month / 12).to_numpy().reshape(-1, 1)
y = co2_data["co2"].to_numpy()
</code></pre>
</div>

<h3 id="model-fitting-using-decision-tree-regression">Model fitting using Decision Tree Regression</h3>

<p>Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.</p>

<p>Decision trees learn from data to approximate a function with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules. Deeper trees are more powerful, but this can lead to overfitting.</p>

<figure>
  
    <img src="/morea/machine-learning/fig/decision_trees.jpg" style="max-width: 60%;" alt="/Basic%20Binder%20Webpage" class="img-fluid mx-auto d-block border" />
  
  <figcaption style="text-align: center">
    <small>
      Image from https://dinhanhthi.com/decision-tree-regression/
    </small>
  </figcaption>
</figure>

<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">from sklearn import tree
regr_1 = tree.DecisionTreeRegressor(max_depth=2)
regr_2 = tree.DecisionTreeRegressor(max_depth=11)
regr_1.fit(X, y)
regr_2.fit(X, y)
</code></pre>
</div>

<p>Now, we will use the the fitted models to predict on:</p>

<p>training data to inspect the goodness of fit;</p>

<p>future data to see the extrapolation done by the models.</p>

<p>Thus, we create synthetic data from 1958 to the current month.</p>

<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">import datetime
import numpy as np

today = datetime.datetime.now()
current_month = today.year + today.month / 12
X_test = np.linspace(start=1958, stop=current_month, num=1_000).reshape(-1, 1)
</code></pre>
</div>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">y_1 = regr_1.predict(X_test)
y_2 = regr_2.predict(X_test)
</code></pre>
</div>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">plt.figure()
plt.scatter(X, y, s=20, edgecolor="black", c="darkorange", label="data")
plt.plot(X_test, y_1, color="cornflowerblue", label=f"max_depth={regr_1.max_depth}", linewidth=2)
plt.plot(X_test, y_2, color="yellowgreen", label=f"max_depth={regr_2.max_depth}", linewidth=2)
plt.xlabel("data")
plt.ylabel("target")
plt.title("Decision Tree Regression")
plt.legend()
plt.show()
</code></pre>
</div>
<figure>
  
    <img src="/morea/machine-learning/fig/co2_decision_trees.png" style="max-width: 60%;" alt="/Basic%20Binder%20Webpage" class="img-fluid mx-auto d-block border" />
  
  <figcaption style="text-align: center">
    <small>
      
    </small>
  </figcaption>
</figure>

<p>As you can see, the decision tree regression was able to fit data within the existing domain quite well. The criteria for decisions is intuitive and can be understood with a simple visualization. However, it has completely failed to predict any future trend outside the domain it was trained on.</p>

<h3 id="model-the-derivative-of-the-data">Model the derivative of the data</h3>

<p>To improve the model’s generalization, we will predict on differences in CO2 rather than absolute CO2 levels, using a “sliding window” of recent CO2 differences as the input. 
We will also normalize the data.</p>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">from sklearn.preprocessing import StandardScaler
from numpy import diff

def preprocess_data(input_data, train_window):
    # Take derivative
    input_data = np.concatenate([[0], diff(input_data)])
    
    # Scale values
    scaler = StandardScaler()
    normalized_data = scaler.fit_transform(input_data.reshape(-1, 1)).reshape(-1)
    
    # Create input-output pairs
    in_seq = []
    out_seq = []
    L = len(normalized_data)
    for i in range(L-train_window-1):
        train_seq = normalized_data[i:i+train_window]
        train_label = normalized_data[i+train_window:i+train_window+1]
        
        in_seq.append(train_seq)
        out_seq.append(train_label)
    return normalized_data, in_seq, out_seq, scaler

train_window = 50
normalized_data, in_data, out_data, scaler = preprocess_data(list(co2_data["co2"]), train_window)
</code></pre>
</div>

<p>We will train 3 decision trees at different max depths.</p>

<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">regr_3 = tree.DecisionTreeRegressor(max_depth=2)
regr_3.fit(in_data, out_data)

regr_4 = tree.DecisionTreeRegressor(max_depth=10)
regr_4.fit(in_data, out_data)

regr_5 = tree.DecisionTreeRegressor(max_depth=25)
regr_5.fit(in_data, out_data)
</code></pre>
</div>

<p>Now we will generate test data that runs all the way to the present day to see the model’s predictions. We use the model’s own prediction as part of the sliding window for the next prediction, to extrapolate arbitrarily far into the future.</p>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">dates = pd.period_range("1958", "2023", freq='M').to_timestamp()


test_inputs = list(normalized_data)
fut_pred_3 = test_inputs.copy()
fut_pred_4 = test_inputs.copy()
fut_pred_5 = test_inputs.copy()
fut_pred_num = len(dates) - len(test_inputs)  # Number of predictions to make.
for i in range(fut_pred_num):
    seq = fut_pred_3[-train_window:]
    prediction = regr_3.predict([seq])
    fut_pred_3.append(prediction[0])
    
    seq = fut_pred_4[-train_window:]
    prediction = regr_4.predict([seq])
    fut_pred_4.append(prediction[0])
    
    seq = fut_pred_5[-train_window:]
    prediction = regr_5.predict([seq])
    fut_pred_5.append(prediction[0])
</code></pre>
</div>

<p>Let’s plot the results. Note that it is still showing the differences (derivative) rather than the absolute value, and it’s still normalized.</p>

<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">plt.figure()
plt.plot(dates, fut_pred_3, label=f"max_depth={regr_3.max_depth}", linewidth=2)
plt.plot(dates, fut_pred_4, label=f"max_depth={regr_4.max_depth}", linewidth=2)
plt.plot(dates, fut_pred_5, label=f"max_depth={regr_5.max_depth}", linewidth=2)
plt.plot(dates[0:526], normalized_data, label=f"true value", linewidth=2)
plt.xlabel("data")
plt.ylabel("target")
plt.title("Decision Tree Regression on Derivative")
plt.legend()
plt.show()
</code></pre>
</div>

<figure>
  
    <img src="/morea/machine-learning/fig/co2_decision_tree_derivative.png" style="max-width: 60%;" alt="/Basic%20Binder%20Webpage" class="img-fluid mx-auto d-block border" />
  
  <figcaption style="text-align: center">
    <small>
      
    </small>
  </figcaption>
</figure>

<p>We can see that all of the decision trees are fitting the past data nearly perfectly, but do not entirely agree on future predictions.</p>

<p>Let’s convert the predictions back into absolute CO2 levels.</p>
<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">def postprocess_data(output_data, scaler, first_input):
    #unscale the output
    output = scaler.inverse_transform(np.array(output_data).reshape(-1, 1)).reshape(-1)
    
    output = np.cumsum(output) + first_input
    
    return output

decoded_3 = postprocess_data(fut_pred_3, scaler, list(co2_data["co2"])[0])
decoded_4 = postprocess_data(fut_pred_4, scaler, list(co2_data["co2"])[0])
decoded_5 = postprocess_data(fut_pred_5, scaler, list(co2_data["co2"])[0])
</code></pre>
</div>

<p>And plot the results:</p>

<div class="alert alert-secondary" role="alert">

  <pre><code class="language-Python">plt.figure()
plt.plot(dates, decoded_3, label=f"max_depth={regr_3.max_depth}", linewidth=2)
plt.plot(dates, decoded_4, label=f"max_depth={regr_4.max_depth}", linewidth=2)
plt.plot(dates, decoded_5, label=f"max_depth={regr_5.max_depth}", linewidth=2)
plt.xlabel("data")
plt.ylabel("target")
plt.title("Decision Tree Regression")
plt.legend()
plt.show()
</code></pre>
</div>

<figure>
  
    <img src="/morea/machine-learning/fig/co2_decision_tree_final.png" style="max-width: 60%;" alt="/Basic%20Binder%20Webpage" class="img-fluid mx-auto d-block border" />
  
  <figcaption style="text-align: center">
    <small>
      
    </small>
  </figcaption>
</figure>

<p>The results can vary quite a bit between runs. The method for fitting the decision trees is stochastic, and our many input variables are all similarly informative, so the tree’s hierarchy can vary significantly. Decision trees are not robust, so slight changes in input or in the tree structure can drastically alter predictions.</p>

<!-- Template code block

<div class="alert alert-secondary" role="alert" markdown="1">

~~~Python

~~~
</div>

-->

<div class="alert alert-info" role="alert">
  <p><i class="fa-solid fa-circle-info fa-xl"></i> <strong>For more information</strong></p>
  <hr />

  <h3 id="attribution">Attribution:</h3>
  <p>This workshop was modified from the following:</p>

  <p><a href="https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_co2.html">Gaussian process regression (GPR) on Mauna Loa CO2 data</a></p>

  <p><a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf">Rasmussen, Carl Edward.
   “Gaussian processes in machine learning.”
   Summer school on machine learning. Springer, Berlin, Heidelberg, 2003</a>.</p>

  <p>Authors:</p>
  <ul>
    <li>Jan Hendrik Metzen <a href="mailto:jhm@informatik.uni-bremen.de">jhm@informatik.uni-bremen.de</a></li>
    <li>Guillaume Lemaitre <a href="mailto:g.lemaitre58@gmail.com">g.lemaitre58@gmail.com</a></li>
  </ul>

  <p>License: BSD 3 clause</p>

  <p><a href="https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html">SciKit-Learn Decision Tree Regression tutorial</a>
<a href="https://scikit-learn.org/stable/modules/tree.html#decision-trees">SciKit-Learn Decision Tree tutorial</a></p>
</div>

<div style="text-align: right; padding-bottom: 10px">
  <hr />
  <button type="button" onclick="window.location='/morea/machine-learning/experience-ml-pytorch.html'" class="btn btn-primary">
    <p style="font-size:16px; margin: 0">Pytorch -&gt;</p>
    <p style="font-size:12px; margin: 0">2:40pm</p>
    </button>
</div>


</div>




<!-- Maybe find a different way?
<script src="/js/scrollIfAnchor.js"></script>
-->

<footer class="footer footer-background" style="padding-top: 1em; padding-bottom: 1em">
  <div class="container text-center">
    
    

    
    <p style="margin: 0">Powered by the <a class="footer-link" href="https://morea-framework.github.io/">Morea Framework</a> (Theme: spacelab)<br>
      Last update on: <span>2023-12-01 13:58:35 -1000</span></p>

    <p style="margin: 0">
      
      18 modules
      
      | 17 outcomes
      
      
      | 55 readings
      
      
      | 100 experiences
      
      
      | 15 assessments
      
    </p>
  </div>
</footer>


<!-- Load Bootstrap JavaScript components -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>


<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
</script>


<!-- Add anchors to pages. -->
<script>anchors.add();</script>


</body>
</html>
